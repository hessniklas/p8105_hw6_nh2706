p8105_hw6_nh2706
================
Niklas Hess
2022-12-03

# Problem 1

SOLUTIONS PROVIDED!

# Problem 2

### Import and cleaning

Importing the data and cleaning it per instructions.

``` r
raw_homicide_df = read_csv("./data/homicide-data.csv", na = c("","Unknown"))
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (8): uid, victim_last, victim_first, victim_race, victim_sex, city, stat...
    ## dbl (4): reported_date, victim_age, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
homicide_df = raw_homicide_df %>%
  mutate(city_state = str_c(city, state, sep = ", ")) %>%
  filter(city_state != "Dallas, TX",
         city_state != "Phoenix, AZ",
         city_state != "Kansas City, MO",
         city_state != "Tulsa, AL",
         victim_race %in%  c("Black", "White")
        ) %>%
  mutate(solution = as.numeric(disposition == "Closed by arrest"),
         victim_age = as.numeric(victim_age),
         victim_race = as.numeric(victim_race == "White"), #White equals 1 and Black equals 0
         victim_sex = as.numeric(victim_sex == "Male")) #Female equals 0 and Male equals 1
```

### Baltimore Analysis

First, using the glm function to fit a logistic regression with resolved
vs unresolved as the outcome and victim age, sex and race as predictors
for Baltimore. Saving the output as an object.

``` r
baltimore_df = homicide_df %>%
  filter(city == "Baltimore") %>%
  glm(solution ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) %>%
  saveRDS(file = "data/baltimore_glm.rds")
```

Second, reading the object and showing the adjusted odds ratio (and CI)
for solving homicides comparing male victims to female victims.

``` r
readRDS(file = "data/baltimore_glm.rds") %>%
  broom::tidy(conf.int = TRUE) %>% 
  janitor::clean_names() %>%
  mutate(OR = exp(estimate),
         conf_low = exp(conf_low),
         conf_high = exp(conf_high)) %>%
  select(term, OR, conf_low, conf_high) %>% 
  filter(term == "victim_sex") %>%
  knitr::kable(digits = 2)
```

| term       |   OR | conf_low | conf_high |
|:-----------|-----:|---------:|----------:|
| victim_sex | 0.43 |     0.32 |      0.56 |

### All city analysis

Runing glm for each of the cities in your dataset, and extract the
adjusted odds ratio (and CI) for solving homicides comparing male
victims to female victims.

``` r
city_list = unique(homicide_df$city_state)

city_function = function(y){
  output = homicide_df %>%
    filter(city_state == y) %>%
    glm(solution ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) %>%
    broom::tidy(conf.int = TRUE) %>% 
    janitor::clean_names() %>%
    mutate(OR = exp(estimate),
         conf_low = exp(conf_low),
         conf_high = exp(conf_high)) %>%
    filter(term == "victim_sex") %>%
    select(term, OR, conf_low, conf_high)
}

final_list = map(city_list, city_function)

df_final = data.frame(city_list[1],final_list[[1]])

names(df_final)[1] = "city_state"

for (i in 2:47) {
  df = data.frame(city_list[i],final_list[[i]])
  names(df)[1] = "city_state"
  df_final = rbind(df_final, df)
}

knitr::kable(df_final, digits = 2)
```

| city_state         | term       |   OR | conf_low | conf_high |
|:-------------------|:-----------|-----:|---------:|----------:|
| Albuquerque, NM    | victim_sex | 1.77 |     0.82 |      3.76 |
| Atlanta, GA        | victim_sex | 1.00 |     0.68 |      1.46 |
| Baltimore, MD      | victim_sex | 0.43 |     0.32 |      0.56 |
| Baton Rouge, LA    | victim_sex | 0.38 |     0.20 |      0.68 |
| Birmingham, AL     | victim_sex | 0.87 |     0.57 |      1.31 |
| Boston, MA         | victim_sex | 0.67 |     0.35 |      1.26 |
| Buffalo, NY        | victim_sex | 0.52 |     0.29 |      0.94 |
| Charlotte, NC      | victim_sex | 0.88 |     0.55 |      1.39 |
| Chicago, IL        | victim_sex | 0.41 |     0.34 |      0.50 |
| Cincinnati, OH     | victim_sex | 0.40 |     0.23 |      0.67 |
| Columbus, OH       | victim_sex | 0.53 |     0.38 |      0.75 |
| Denver, CO         | victim_sex | 0.48 |     0.23 |      0.96 |
| Detroit, MI        | victim_sex | 0.58 |     0.46 |      0.73 |
| Durham, NC         | victim_sex | 0.81 |     0.38 |      1.66 |
| Fort Worth, TX     | victim_sex | 0.67 |     0.39 |      1.12 |
| Fresno, CA         | victim_sex | 1.34 |     0.57 |      3.05 |
| Houston, TX        | victim_sex | 0.71 |     0.56 |      0.91 |
| Indianapolis, IN   | victim_sex | 0.92 |     0.68 |      1.24 |
| Jacksonville, FL   | victim_sex | 0.72 |     0.54 |      0.97 |
| Las Vegas, NV      | victim_sex | 0.84 |     0.61 |      1.15 |
| Long Beach, CA     | victim_sex | 0.41 |     0.14 |      1.02 |
| Los Angeles, CA    | victim_sex | 0.66 |     0.46 |      0.95 |
| Louisville, KY     | victim_sex | 0.49 |     0.30 |      0.78 |
| Memphis, TN        | victim_sex | 0.72 |     0.53 |      0.98 |
| Miami, FL          | victim_sex | 0.52 |     0.30 |      0.87 |
| Milwaukee, wI      | victim_sex | 0.73 |     0.50 |      1.05 |
| Minneapolis, MN    | victim_sex | 0.95 |     0.48 |      1.88 |
| Nashville, TN      | victim_sex | 1.03 |     0.68 |      1.56 |
| New Orleans, LA    | victim_sex | 0.58 |     0.42 |      0.81 |
| New York, NY       | victim_sex | 0.26 |     0.13 |      0.49 |
| Oakland, CA        | victim_sex | 0.56 |     0.36 |      0.87 |
| Oklahoma City, OK  | victim_sex | 0.97 |     0.62 |      1.52 |
| Omaha, NE          | victim_sex | 0.38 |     0.20 |      0.71 |
| Philadelphia, PA   | victim_sex | 0.50 |     0.38 |      0.65 |
| Pittsburgh, PA     | victim_sex | 0.43 |     0.26 |      0.70 |
| Richmond, VA       | victim_sex | 1.01 |     0.48 |      1.99 |
| San Antonio, TX    | victim_sex | 0.70 |     0.39 |      1.24 |
| Sacramento, CA     | victim_sex | 0.67 |     0.33 |      1.31 |
| Savannah, GA       | victim_sex | 0.87 |     0.42 |      1.78 |
| San Bernardino, CA | victim_sex | 0.50 |     0.17 |      1.46 |
| San Diego, CA      | victim_sex | 0.41 |     0.19 |      0.83 |
| San Francisco, CA  | victim_sex | 0.61 |     0.31 |      1.16 |
| St. Louis, MO      | victim_sex | 0.70 |     0.53 |      0.93 |
| Stockton, CA       | victim_sex | 1.35 |     0.63 |      2.99 |
| Tampa, FL          | victim_sex | 0.81 |     0.34 |      1.86 |
| Tulsa, OK          | victim_sex | 0.98 |     0.61 |      1.54 |
| Washington, DC     | victim_sex | 0.69 |     0.47 |      1.01 |

### Plotting results

Creating a plot that shows the estimated ORs and CIs for each city.
Organizing cities according to estimated OR, and comment on the plot.
Important to note that Male equals to 1, which means Female is the
reference category.

``` r
city_graph = df_final %>%
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf_low, ymax = conf_high)) +
  labs(
    title = "Estimated ORs and related CIs for each city",
    x = "City_State",
    y = "ORs") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

city_graph
```

<img src="p8105_hw6_nh2706_files/figure-gfm/unnamed-chunk-5-1.png" width="90%" />
Looking at the graph it becomes clear that the odd of solving a homicide
comparing male victims to female victims varies widely. Two examples:

-   In NYC, the odds of solving a homicide for a male are 0.26 (CI:
    0.13, 0.49) times the odds of solvings a homicide for females.
-   In Albuquerque, the odds of solving a homicide for a male are 1.77
    (CI: 0.82, 3.76) times the odds of solvings a homicide for females.
    However, the 95% confidence interval includes 1, so likely not
    significant.

# Problem 3

### Loading and cleaning the data for regression analysis

``` r
birthweight_df = read_csv("./data/birthweight.csv") %>% 
  mutate(babysex = factor(if_else(babysex == 1, "male", "female")),
         frace = factor(recode(frace, '1' = "White", '2' = "Black", '3' = "Asian", 
                               '4' = "Puerto Rican", '8' = "Other", '9' = "Unknown")),
         mrace = factor(recode(mrace,'1' = "White", '2' = "Black", '3' = "Asian", 
                               '4' = "Puerto Rican", '8' = "Other", '9' = "Unknown")),
         malform = factor(recode(malform, '0' = "absent", '1' = "present")))
```

    ## Rows: 4342 Columns: 20
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (20): babysex, bhead, blength, bwt, delwt, fincome, frace, gaweeks, malf...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
sum(is.na(birthweight_df))
```

    ## [1] 0

### Proposing a regression model for birthweight

``` r
birthweight_df %>%
  select(-babysex,-frace,-malform,-mrace,-pnumlbw,-pnumsga) %>%
  cor(method = "pearson") %>%
  corrplot(method = "number")
```

<img src="p8105_hw6_nh2706_files/figure-gfm/unnamed-chunk-7-1.png" width="90%" />
First, I create a correlation table. The two variables with the highest
correlation with ‘BWT’ are ‘BHEAD’, ‘GAWEEKS’ and ‘BLENGTH’. Therefore,
I will use those three variables within my regression model.

``` r
bwt_reg1 = lm(bwt ~ blength + gaweeks + bhead, data = birthweight_df) 

bwt_reg1 %>%   
  broom::tidy() %>% 
  knitr::kable(digits = 2)
```

| term        | estimate | std.error | statistic | p.value |
|:------------|---------:|----------:|----------:|--------:|
| (Intercept) | -6195.57 |     96.35 |    -64.30 |       0 |
| blength     |    81.64 |      2.08 |     39.18 |       0 |
| gaweeks     |    14.60 |      1.51 |      9.68 |       0 |
| bhead       |   138.85 |      3.53 |     39.32 |       0 |

Second, I am constructing the linear model, including the aforementioned
variables.

``` r
birthweight_df %>% 
  modelr::add_residuals(bwt_reg1) %>% 
  modelr::add_predictions(bwt_reg1) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = .3) +
  labs(title = "Residuals against fitted values plot for Reg1 model",
       x = "Fitted Values",
       y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5))
```

<img src="p8105_hw6_nh2706_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />
Third, I am showing a plot of model residuals against fitted values. The
plot shows that the linearity assumption likely holds.

### Comparing regression model to two others

#### Creating the two other models and checking their residuals vs. fitted values

Model \#2: Using length at birth and gestational age as predictors (main
effects only)

``` r
bwt_reg2 = lm(bwt ~ blength + gaweeks, data = birthweight_df) 

bwt_reg2 %>%   
  broom::tidy() %>% 
  knitr::kable(digits = 2)
```

| term        | estimate | std.error | statistic | p.value |
|:------------|---------:|----------:|----------:|--------:|
| (Intercept) | -4347.67 |     97.96 |    -44.38 |       0 |
| blength     |   128.56 |      1.99 |     64.60 |       0 |
| gaweeks     |    27.05 |      1.72 |     15.74 |       0 |

``` r
birthweight_df %>% 
  modelr::add_residuals(bwt_reg2) %>% 
  modelr::add_predictions(bwt_reg2) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = .3) +
  labs(title = "Residuals against fitted values plot for Reg2 model",
       x = "Fitted Values",
       y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5))
```

<img src="p8105_hw6_nh2706_files/figure-gfm/unnamed-chunk-10-1.png" width="90%" />

Model \#3: Using head circumference, length, sex, and all interactions
(including the three-way interaction)

``` r
bwt_reg3 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = birthweight_df) 

bwt_reg3 %>%   
  broom::tidy() %>% 
  knitr::kable(digits = 2)
```

| term                      | estimate | std.error | statistic | p.value |
|:--------------------------|---------:|----------:|----------:|--------:|
| (Intercept)               |  -801.95 |   1102.31 |     -0.73 |    0.47 |
| bhead                     |   -16.60 |     34.09 |     -0.49 |    0.63 |
| blength                   |   -21.65 |     23.37 |     -0.93 |    0.35 |
| babysexmale               | -6374.87 |   1677.77 |     -3.80 |    0.00 |
| bhead:blength             |     3.32 |      0.71 |      4.67 |    0.00 |
| bhead:babysexmale         |   198.39 |     51.09 |      3.88 |    0.00 |
| blength:babysexmale       |   123.77 |     35.12 |      3.52 |    0.00 |
| bhead:blength:babysexmale |    -3.88 |      1.06 |     -3.67 |    0.00 |

``` r
birthweight_df %>% 
  modelr::add_residuals(bwt_reg3) %>% 
  modelr::add_predictions(bwt_reg3) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = .3) +
  labs(title = "Residuals against fitted values plot for Reg3 model",
       x = "Fitted Values",
       y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5))
```

<img src="p8105_hw6_nh2706_files/figure-gfm/unnamed-chunk-11-1.png" width="90%" />

#### Compariing using the cross-validated prediction error

``` r
cv_df = 
  crossv_mc(birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>% 
  mutate(
    model_bwt_reg1 = 
      map(train, ~lm(bwt ~ blength + gaweeks + bhead, data = birthweight_df)),
    model_bwt_reg2 = 
      map(train, ~lm(bwt ~ blength + gaweeks, data = birthweight_df)),
    model_bwt_reg3 = 
      map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = birthweight_df))
  ) %>% 
  mutate(
    rmse_bwt_reg1 = map2_dbl(model_bwt_reg1, test, ~rmse(model = .x, data = .y)),
    rmse_bwt_reg2 = map2_dbl(model_bwt_reg2, test, ~rmse(model = .x, data = .y)),
    rmse_bwt_reg3 = map2_dbl(model_bwt_reg3, test, ~rmse(model = .x, data = .y))
  )
  
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_bwt_reg") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  labs(
    title = "RMSE values for three candidate model",
    x = "Model",
    y = "RMSEs"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
```

<img src="p8105_hw6_nh2706_files/figure-gfm/unnamed-chunk-12-1.png" width="90%" />

The violin graph above shows that model 1 and model 3 have a very
similar RMSE score. As such, it would require some further investigation
to decide which model is the best. Nevertheless, model 2 has a very high
RMSE score and can be excluded.

# END
